{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAC-2 Code And Details\n",
    "This notebook contains all code and explanations of said code. Code is separated into blocks, organised and split by purpose of code. \n",
    "\n",
    "The method used for this assessment to evolve agents throughout gameplay was a neural network, where weights of said neural network are evolved generation by generation. Further detail can be found at the relevant code sections within this report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Representation\n",
    "As each agent is required to be part of a group, groups were defined as an integer with representation as follows:\n",
    "* `0` - Saints\n",
    "* `1` - Buddies\n",
    "* `2` - Fight Club\n",
    "* `3` - Vandals\n",
    "\n",
    "An agent was decided to be represented using the class `Player`, this class could then be used to keep track of all important agent attributes:\n",
    "* `wealth` - The total wealth of the agent.\n",
    "* `startingGroup` - The initial group assignment of the agent, reassigned each generation start. This is randomly allocated when the agent is first created.\n",
    "* `group` - The current group assignment of the agent.\n",
    "* `gameCount` - The number of games played by the agent.\n",
    "* `weights` - List of floats used in the neural network to make a decision on which group to join. Evolved by the evolutionary algorithm.\n",
    "* `fitness` - Current fitness of the agent. \n",
    "\n",
    "The game can be played by calling the `getPayoff()` method with the opponent as the required parameter. This is called for each of the two agents chosen in a single game as each agent assumes the role of opponent to the other. Representing each group as an integer allows for very simple calculation of payoffs, with a lookup table implemented for each agent as follows: `[[4,0,4,0],[6,4,6,1],[4,0,1,0],[6,1,6,0]]`. This lookup table stores the payoffs for each group interaction with each group, for a total of 16 different possible interactions. \n",
    "\n",
    "The evolutionary aspect of the player class is called with `evaluate()`, with the required parameters of the current game opponent along with an instance of the neural network class. This method loads the agent weights into the neural network, calculates the group that the agent should be assigned to (this is the agent deciding if it should move group) and then the agent fitness is assigned as the agent wealth divided by the game count. This fitness was chosen to allow for a fair comparison between agents regardless of how many games they were randomly chosen to play.\n",
    "\n",
    "The `reset()` method is called to setup an agent ready for a new generation. This resets the group to the agents starting group, along with setting the agent wealth, fitness, and game counter to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Player():\n",
    "  '''\n",
    "  stores all data required by one agent\n",
    "  '''\n",
    "  def __init__(self, IND_SIZE):\n",
    "    '''\n",
    "    initialises an agent ready to play a game \n",
    "\n",
    "    args:\n",
    "      int IND_SIZE - size of neural network, therefore number of weights required\n",
    "    '''\n",
    "    self.wealth = 0\n",
    "    # starting group randomly selected\n",
    "    self.startingGroup = random.randint(0,3)\n",
    "    # current group agent is a member of \n",
    "    self.group = self.startingGroup\n",
    "    self.gameCount = 0\n",
    "    # weights to be used in the neural network, randomly initially assigned\n",
    "    self.weights = tools.initRepeat(list, toolbox.attr_float, IND_SIZE)\n",
    "    self.fitness = 0\n",
    "  \n",
    "  def evaluate(self,opponent,network):\n",
    "    '''\n",
    "    calculate agent group decision and fitness\n",
    "\n",
    "    args:\n",
    "      Player opponent - player instance of the opponent this agent is playing against\n",
    "      NeuralNetwork - network - neural network instance to apply weights to and make group decision\n",
    "    '''\n",
    "    # set agent weights in network\n",
    "    network.setWeightsLinear(self.weights)\n",
    "    # get group output from neural network\n",
    "    output = network.feedForward([self.wealth, self.group, opponent.wealth, opponent.group])\n",
    "    self.group = np.argmax(output, axis=0)\n",
    "    # set fitness as agent average payoff\n",
    "    self.fitness = self.wealth / self.gameCount\n",
    "\n",
    "  def addPayoff(self, opponent):\n",
    "    '''\n",
    "    calculate agent payoff, add to wealth and increment game counter\n",
    "\n",
    "    args:\n",
    "      Player opponent - player instance of the opponent this agent is playing against\n",
    "    '''\n",
    "    # payoff lookup table\n",
    "    payoffs = [[4,0,4,0],[6,4,6,1],[4,0,1,0],[6,1,6,0]]\n",
    "    # add value from relevant value in lookup table\n",
    "    self.wealth += payoffs[self.group][opponent.group]\n",
    "    self.gameCount += 1\n",
    "\n",
    "  def reset(self):\n",
    "    '''\n",
    "    reset agent ready for the next generation\n",
    "    '''\n",
    "    self.wealth = 0\n",
    "    self.gameCount = 0\n",
    "    self.group = self.startingGroup\n",
    "    self.fitness = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Evolution Environment\n",
    "\n",
    "### Neural Network\n",
    "The neural network used by all agents in the system is a single hidden layer network with 4 input nodes, 8 hidden nodes and 4 output nodes. These 4 output nodes represent the decision of which group to join, and a group is selected using a `softmax` function. The input nodes of this neural network are the agents own group, the agents own wealth, the opponents group and the opponents wealth. These inputs were settled on after experimentation with other inputs such as the number of games the agent had played, or the current game number. These additional inputs did not improve performance and were removed to reduce chance of overfitting.\n",
    "\n",
    "A bias of 1 was added to the input layer to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# layer node count\n",
    "numInputNodes = 4\n",
    "numHiddenNodes = 8\n",
    "numOutputNodes = 4\n",
    "\n",
    "# number of weights required by neural network\n",
    "IND_SIZE = ((numInputNodes+1) * numHiddenNodes) +  + (numHiddenNodes * numOutputNodes)\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "  '''\n",
    "  neural network for decision on which group agent should join\n",
    "  '''\n",
    "  def __init__(self, numInput, numHidden, numOutput):\n",
    "    '''\n",
    "    initialises neural network ready for use\n",
    "\n",
    "    args:\n",
    "      int numInput - number of input nodes\n",
    "      int numHidden - number of hidden nodes in single hidden node layer\n",
    "      int numOutput - number of output nodes (1 per group)\n",
    "    '''\n",
    "    self.numInput = numInput + 1\n",
    "    self.numHidden = numHidden\n",
    "    self.numOutput = numOutput\n",
    "\n",
    "    # generate some basic weights for the network\n",
    "    self.wh = np.random.randn(self.numHidden, self.numInput) \n",
    "    self.wo = np.random.randn(self.numOutput, self.numHidden)\n",
    "\n",
    "    # rectified linear unit to be used in hidden layer\n",
    "    self.ReLU = lambda x : max(0,x)\n",
    "\n",
    "  def softmax(self, x):\n",
    "    '''\n",
    "    used to normalise output layer\n",
    "\n",
    "    args:\n",
    "      list (float) x - output layer of neural network\n",
    "    return:\n",
    "      softmax of x\n",
    "    '''\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "  def feedForward(self, inputs):\n",
    "    '''\n",
    "    run inputs through neural network\n",
    "\n",
    "    args:\n",
    "      list inputs - neural network inputs\n",
    "    return:\n",
    "      softmax output of network\n",
    "    '''\n",
    "    # add data to input layer\n",
    "    inputsBias = inputs[:]\n",
    "    inputsBias.insert(len(inputs), 1)\n",
    "\n",
    "    # feed input layer to hidden layer\n",
    "    h1 = np.dot(self.wh, inputsBias)\n",
    "    h1 = [self.ReLU(x) for x in h1]\n",
    "\n",
    "    # feed hidden layer to output layer\n",
    "    output = np.dot(self.wo, h1)\n",
    "    return self.softmax(output)\n",
    "\n",
    "  def setWeightsLinear(self, Wgenome):\n",
    "    '''\n",
    "    set given weights for neural network\n",
    "\n",
    "    args:\n",
    "      list (float) Wgenome - list of weights evolved by an agent\n",
    "    '''\n",
    "    numWeights_IH = self.numHidden * (self.numInput)\n",
    "    # set hidden layer weights\n",
    "    self.wh = np.array(Wgenome[:numWeights_IH])\n",
    "    self.wh = self.wh.reshape((self.numHidden, self.numInput))\n",
    "    # set output layer weights\n",
    "    self.wo = np.array(Wgenome[numWeights_IH:])\n",
    "    self.wo = self.wo.reshape((self.numOutput, self.numHidden))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Simulation\n",
    "The game simulation is defined as: for a set number of games, two agents are selected at random from a population to play against each other. Payoffs are calculated and each agent is then given the opportunity to change groups. \n",
    "\n",
    "This is implemented within the method `playGameAndEvolve` using the constant `NGAMES` to define the number of games played, and `POP` to specify the population size. The two agents are selected using the code `random.sample(range(POP),2)`, which selects two distinct population indexes, these agents then calculate their respective payoffs using `addPayoff`, and calculate their fitness and decision on if they should migrate groups using `evaluate`. Details of these methods are found in the Agent Representation part of this code.\n",
    "\n",
    "`playBasicGame` is an additional method that can be used to run the game without allowing agents to swap their group assignments, this will be used to evaluate the behaviour developed through adaption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set game number and population\n",
    "NGAMES = 20000\n",
    "POP = 1000\n",
    "\n",
    "def playGameAndEvolve(pop, network):\n",
    "  '''\n",
    "  play NGAMES number of games, allowing agents to make decisions on when to change groups using the neural network\n",
    "\n",
    "  args:\n",
    "    list (Player) pop - population of agents\n",
    "    NeuralNetwork network - neural network to use to evaluate\n",
    "  return:\n",
    "    population\n",
    "  '''\n",
    "  for r in range(NGAMES):\n",
    "    # randomly select two distinct agents\n",
    "    selection = random.sample(range(POP),2)\n",
    "    # calculate each agent payoff\n",
    "    pop[selection[0]].addPayoff(pop[selection[1]])\n",
    "    pop[selection[1]].addPayoff(pop[selection[0]])\n",
    "    # give each agent the opportunity to change groups\n",
    "    pop[selection[0]].evaluate(pop[selection[1]],network)\n",
    "    pop[selection[1]].evaluate(pop[selection[0]],network)\n",
    "  return pop\n",
    "\n",
    "def playBasicGame(pop):\n",
    "  '''\n",
    "  play NGAMES number of games, do not use the neural network or allow agents to change groups\n",
    "\n",
    "  args:\n",
    "    list (Player) pop - population of agents\n",
    "  return:\n",
    "    population\n",
    "  '''\n",
    "  for r in range(NGAMES):\n",
    "    # randomly select two distinct agents\n",
    "    selection = random.sample(range(POP),2)\n",
    "    # calculate each agent payoff\n",
    "    pop[selection[0]].addPayoff(pop[selection[1]])\n",
    "    pop[selection[1]].addPayoff(pop[selection[0]])\n",
    "  return pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Adaptation Procedure (Training through Evolution)\n",
    "Below are some helpful methods to keep track of population performance through evolution. `countGroups()` gets number of agents in each group, while `fitnessStats()` gets the mean, minimum and maximum fitness values for the whole population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countGroups(pop):\n",
    "  '''\n",
    "  get the total number of agents in each group\n",
    "\n",
    "  args:\n",
    "    list (Player) pop - population of agents\n",
    "  return:\n",
    "    int list of counts of each group\n",
    "  '''\n",
    "  groupTotals=[0,0,0,0]\n",
    "  for person in pop:\n",
    "    groupTotals[person.group] += 1\n",
    "  return groupTotals\n",
    "\n",
    "def fitnessStats(pop):\n",
    "  '''\n",
    "  calculate fitness statistics of the population\n",
    "\n",
    "  args:\n",
    "    list (Player) pop - population of agents\n",
    "  return:\n",
    "    dictionary of mean, max, min of agent fitness\n",
    "  '''\n",
    "  fitnessSum = 0\n",
    "  fitnessMax = 0 \n",
    "  fitnessMin = -1\n",
    "  for person in pop:\n",
    "    # set highest fitness\n",
    "    if(person.fitness > fitnessMax):\n",
    "      fitnessMax = person.fitness\n",
    "    # set lowest fitness\n",
    "    if(person.fitness < fitnessMin or fitnessMin == -1):\n",
    "      fitnessMin = person.fitness\n",
    "    # sum fitness to be divided for mean\n",
    "    fitnessSum += person.fitness\n",
    "  return { \"mean\": fitnessSum/len(pop), \"max\":fitnessMax, \"min\":fitnessMin }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolutionary training method\n",
    "To evolve each agents neural network weightings, the python module `DEAP` has been used. `DEAP` allows for easy crossover, mutation and selection of the population:\n",
    "* Crossover - Defined as `mate` within the `DEAP` toolbox, implemented using the `cxOnePoint` method. Probability of crossover for each individual is defined by constant `CXPB` set to `0.1`.\n",
    "* Mutation - Defined as `mutate` within the `DEAP` toolbox, implemented using the `mutGaussian` method with the parameters `mu=0.0, sigma=0.5, indpb=INDPB`. Probability of an individual being subject to mutation is defined by constant `MUTPB` set to `0.5`, and probability of each chromosome within a selected individual (neural network weight in this implementation) being mutated is defined by constant `INDPB` set to `0.1`. \n",
    "* Selection - Defined as `select` within the `DEAP` toolbox, implemented using the `selTournament` method with a tournament size of 3.\n",
    "* Generations - Number of generations is defined by constant `NGEN` set to `100`.\n",
    "\n",
    "Once these toolbox commands are setup, a population of constant size `POP` (set to 1000) is generated using `DEAP` where an individual in that population is an instance of the previously discussed `player` class. An instance of the neural network is also initialized to be used by the agents in the population. The game is then played with this initial population and fitness information is output. Generational evolution then begins.\n",
    "\n",
    "For each generation, tournament selection is used to select a new population of agents based on the fitness of the previous generation. This new population is then subject to crossover and mutation for each agents neural network weights. During mutation an individual also has a chance to mutate its starting group to another randomly selected group. This has the same probability of being mutated as each weight in an agent does. All agents in the population are then reset to their starting values (wealth, group, fitness and number of games played), the game then is played with this new population and fitness information for this new population is output. The next generation then begins.\n",
    "\n",
    "Using this method, a population uses multi-agent evolution to evolve as each game pits agents against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Generation 1 --\n",
      "Fitness avg    :2.740287813822427\n",
      "Fitness max    :4.9743589743589745\n",
      "Group count  : [263, 273, 235, 229]\n",
      "-- Generation 2 --\n",
      "Fitness avg    :2.43138342730047\n",
      "Fitness max    :4.28125\n",
      "Group count  : [138, 474, 82, 306]\n",
      "-- Generation 3 --\n",
      "Fitness avg    :3.040486711288989\n",
      "Fitness max    :4.514285714285714\n",
      "Group count  : [60, 739, 55, 146]\n",
      "-- Generation 4 --\n",
      "Fitness avg    :3.5040598850284423\n",
      "Fitness max    :4.48\n",
      "Group count  : [40, 875, 34, 51]\n",
      "-- Generation 5 --\n",
      "Fitness avg    :3.639678103787246\n",
      "Fitness max    :4.444444444444445\n",
      "Group count  : [27, 905, 35, 33]\n",
      "-- Generation 6 --\n",
      "Fitness avg    :3.710721940116971\n",
      "Fitness max    :4.454545454545454\n",
      "Group count  : [24, 927, 22, 27]\n",
      "-- Generation 7 --\n",
      "Fitness avg    :3.738112760204881\n",
      "Fitness max    :4.4\n",
      "Group count  : [24, 935, 20, 21]\n",
      "-- Generation 8 --\n",
      "Fitness avg    :3.756242152185986\n",
      "Fitness max    :4.326530612244898\n",
      "Group count  : [37, 932, 12, 19]\n",
      "-- Generation 9 --\n",
      "Fitness avg    :3.77725236161427\n",
      "Fitness max    :4.344827586206897\n",
      "Group count  : [14, 937, 29, 20]\n",
      "-- Generation 10 --\n",
      "Fitness avg    :3.7922127514154256\n",
      "Fitness max    :4.333333333333333\n",
      "Group count  : [26, 940, 18, 16]\n",
      "-- Generation 11 --\n",
      "Fitness avg    :3.7839368056569156\n",
      "Fitness max    :4.333333333333333\n",
      "Group count  : [21, 941, 15, 23]\n",
      "-- Generation 12 --\n",
      "Fitness avg    :3.785217250928382\n",
      "Fitness max    :4.258064516129032\n",
      "Group count  : [16, 943, 15, 26]\n",
      "-- Generation 13 --\n",
      "Fitness avg    :3.8358711117412105\n",
      "Fitness max    :4.260869565217392\n",
      "Group count  : [13, 950, 22, 15]\n",
      "-- Generation 14 --\n",
      "Fitness avg    :3.8307398912810244\n",
      "Fitness max    :4.323529411764706\n",
      "Group count  : [22, 945, 18, 15]\n",
      "-- Generation 15 --\n",
      "Fitness avg    :3.83913319498074\n",
      "Fitness max    :4.25\n",
      "Group count  : [10, 956, 17, 17]\n",
      "-- Generation 16 --\n",
      "Fitness avg    :3.8340101809382023\n",
      "Fitness max    :4.296296296296297\n",
      "Group count  : [15, 955, 12, 18]\n",
      "-- Generation 17 --\n",
      "Fitness avg    :3.8301636026782266\n",
      "Fitness max    :4.285714285714286\n",
      "Group count  : [14, 950, 20, 16]\n",
      "-- Generation 18 --\n",
      "Fitness avg    :3.8816566153575005\n",
      "Fitness max    :4.266666666666667\n",
      "Group count  : [12, 964, 13, 11]\n",
      "-- Generation 19 --\n",
      "Fitness avg    :3.8223345205965247\n",
      "Fitness max    :4.258064516129032\n",
      "Group count  : [18, 945, 19, 18]\n",
      "-- Generation 20 --\n",
      "Fitness avg    :3.8343379633733425\n",
      "Fitness max    :4.303030303030303\n",
      "Group count  : [13, 956, 12, 19]\n",
      "-- Generation 21 --\n",
      "Fitness avg    :3.7868100498323973\n",
      "Fitness max    :4.384615384615385\n",
      "Group count  : [13, 941, 23, 23]\n",
      "-- Generation 22 --\n",
      "Fitness avg    :3.8789532553240993\n",
      "Fitness max    :4.266666666666667\n",
      "Group count  : [10, 965, 12, 13]\n",
      "-- Generation 23 --\n",
      "Fitness avg    :3.8694690653206876\n",
      "Fitness max    :4.285714285714286\n",
      "Group count  : [11, 960, 15, 14]\n",
      "-- Generation 24 --\n",
      "Fitness avg    :3.854765528329478\n",
      "Fitness max    :4.27027027027027\n",
      "Group count  : [9, 960, 20, 11]\n",
      "-- Generation 25 --\n",
      "Fitness avg    :3.8585021099845056\n",
      "Fitness max    :4.333333333333333\n",
      "Group count  : [10, 958, 22, 10]\n",
      "-- Generation 26 --\n",
      "Fitness avg    :3.8577973669497894\n",
      "Fitness max    :4.285714285714286\n",
      "Group count  : [14, 961, 15, 10]\n",
      "-- Generation 27 --\n",
      "Fitness avg    :3.854183130668602\n",
      "Fitness max    :4.237288135593221\n",
      "Group count  : [9, 958, 17, 16]\n",
      "-- Generation 28 --\n",
      "Fitness avg    :3.8808332452646708\n",
      "Fitness max    :4.344827586206897\n",
      "Group count  : [10, 966, 14, 10]\n",
      "-- Generation 29 --\n",
      "Fitness avg    :3.885084196901957\n",
      "Fitness max    :4.285714285714286\n",
      "Group count  : [15, 963, 10, 12]\n",
      "-- Generation 30 --\n",
      "Fitness avg    :3.9137016192830405\n",
      "Fitness max    :4.222222222222222\n",
      "Group count  : [6, 973, 12, 9]\n",
      "-- Generation 31 --\n",
      "Fitness avg    :3.8776085605690365\n",
      "Fitness max    :4.2105263157894735\n",
      "Group count  : [8, 967, 10, 15]\n",
      "-- Generation 32 --\n",
      "Fitness avg    :3.8749744944406657\n",
      "Fitness max    :4.294117647058823\n",
      "Group count  : [16, 959, 15, 10]\n",
      "-- Generation 33 --\n",
      "Fitness avg    :3.886582013268565\n",
      "Fitness max    :4.222222222222222\n",
      "Group count  : [13, 967, 9, 11]\n",
      "-- Generation 34 --\n",
      "Fitness avg    :3.89841698252538\n",
      "Fitness max    :4.3478260869565215\n",
      "Group count  : [15, 968, 11, 6]\n",
      "-- Generation 35 --\n",
      "Fitness avg    :3.9037822040915753\n",
      "Fitness max    :4.2105263157894735\n",
      "Group count  : [5, 975, 10, 10]\n",
      "-- Generation 36 --\n",
      "Fitness avg    :3.932090317137054\n",
      "Fitness max    :4.238095238095238\n",
      "Group count  : [7, 976, 14, 3]\n",
      "-- Generation 37 --\n",
      "Fitness avg    :3.9237890459985367\n",
      "Fitness max    :4.27027027027027\n",
      "Group count  : [5, 978, 10, 7]\n",
      "-- Generation 38 --\n",
      "Fitness avg    :3.860776121618155\n",
      "Fitness max    :4.285714285714286\n",
      "Group count  : [6, 958, 21, 15]\n",
      "-- Generation 39 --\n",
      "Fitness avg    :3.878559338823318\n",
      "Fitness max    :4.285714285714286\n",
      "Group count  : [5, 962, 23, 10]\n",
      "-- Generation 40 --\n",
      "Fitness avg    :3.9282935118289064\n",
      "Fitness max    :4.242424242424242\n",
      "Group count  : [5, 981, 9, 5]\n",
      "-- Generation 41 --\n",
      "Fitness avg    :3.8721386156102766\n",
      "Fitness max    :4.228571428571429\n",
      "Group count  : [3, 967, 11, 19]\n",
      "-- Generation 42 --\n",
      "Fitness avg    :3.904817008001209\n",
      "Fitness max    :4.216216216216216\n",
      "Group count  : [5, 972, 12, 11]\n",
      "-- Generation 43 --\n",
      "Fitness avg    :3.907767198417674\n",
      "Fitness max    :4.25\n",
      "Group count  : [6, 972, 16, 6]\n",
      "-- Generation 44 --\n",
      "Fitness avg    :3.8985577129397075\n",
      "Fitness max    :4.230769230769231\n",
      "Group count  : [8, 970, 13, 9]\n",
      "-- Generation 45 --\n",
      "Fitness avg    :3.9225283190807865\n",
      "Fitness max    :4.235294117647059\n",
      "Group count  : [1, 978, 12, 9]\n",
      "-- Generation 46 --\n",
      "Fitness avg    :3.9111220156618103\n",
      "Fitness max    :4.153846153846154\n",
      "Group count  : [4, 979, 9, 8]\n",
      "-- Generation 47 --\n",
      "Fitness avg    :3.912833781755958\n",
      "Fitness max    :4.190476190476191\n",
      "Group count  : [9, 975, 7, 9]\n",
      "-- Generation 48 --\n",
      "Fitness avg    :3.8993160682137704\n",
      "Fitness max    :4.2105263157894735\n",
      "Group count  : [4, 973, 13, 10]\n",
      "-- Generation 49 --\n",
      "Fitness avg    :3.917361317713622\n",
      "Fitness max    :4.275862068965517\n",
      "Group count  : [7, 973, 14, 6]\n",
      "-- Generation 50 --\n",
      "Fitness avg    :3.9389408719698373\n",
      "Fitness max    :4.285714285714286\n",
      "Group count  : [7, 980, 7, 6]\n",
      "-- Generation 51 --\n",
      "Fitness avg    :3.9286882975148063\n",
      "Fitness max    :4.2105263157894735\n",
      "Group count  : [4, 982, 10, 4]\n",
      "-- Generation 52 --\n",
      "Fitness avg    :3.9141706470635778\n",
      "Fitness max    :4.294117647058823\n",
      "Group count  : [7, 975, 10, 8]\n",
      "-- Generation 53 --\n",
      "Fitness avg    :3.9410881282853842\n",
      "Fitness max    :4.2\n",
      "Group count  : [1, 984, 12, 3]\n",
      "-- Generation 54 --\n",
      "Fitness avg    :3.9292413933342427\n",
      "Fitness max    :4.136363636363637\n",
      "Group count  : [3, 983, 4, 10]\n",
      "-- Generation 55 --\n",
      "Fitness avg    :3.9335784175122073\n",
      "Fitness max    :4.205128205128205\n",
      "Group count  : [10, 976, 9, 5]\n",
      "-- Generation 56 --\n",
      "Fitness avg    :3.9440503271936795\n",
      "Fitness max    :4.193548387096774\n",
      "Group count  : [5, 987, 2, 6]\n",
      "-- Generation 57 --\n",
      "Fitness avg    :3.9635342166916394\n",
      "Fitness max    :4.177777777777778\n",
      "Group count  : [4, 988, 5, 3]\n",
      "-- Generation 58 --\n",
      "Fitness avg    :3.94546386119049\n",
      "Fitness max    :4.2105263157894735\n",
      "Group count  : [7, 982, 8, 3]\n",
      "-- Generation 59 --\n",
      "Fitness avg    :3.9516744440481424\n",
      "Fitness max    :4.195121951219512\n",
      "Group count  : [8, 981, 9, 2]\n",
      "-- Generation 60 --\n",
      "Fitness avg    :3.933140849684592\n",
      "Fitness max    :4.222222222222222\n",
      "Group count  : [3, 978, 13, 6]\n",
      "-- Generation 61 --\n",
      "Fitness avg    :3.932010408105854\n",
      "Fitness max    :4.285714285714286\n",
      "Group count  : [4, 982, 7, 7]\n",
      "-- Generation 62 --\n",
      "Fitness avg    :3.9286483684696214\n",
      "Fitness max    :4.195121951219512\n",
      "Group count  : [9, 977, 8, 6]\n",
      "-- Generation 63 --\n",
      "Fitness avg    :3.912840725885464\n",
      "Fitness max    :4.218181818181818\n",
      "Group count  : [9, 976, 7, 8]\n",
      "-- Generation 64 --\n",
      "Fitness avg    :3.9281295926033954\n",
      "Fitness max    :4.258064516129032\n",
      "Group count  : [7, 973, 16, 4]\n",
      "-- Generation 65 --\n",
      "Fitness avg    :3.9300691018333485\n",
      "Fitness max    :4.2\n",
      "Group count  : [3, 978, 10, 9]\n",
      "-- Generation 66 --\n",
      "Fitness avg    :3.9321697898934085\n",
      "Fitness max    :4.25\n",
      "Group count  : [4, 981, 8, 7]\n",
      "-- Generation 67 --\n",
      "Fitness avg    :3.92636011253524\n",
      "Fitness max    :4.27027027027027\n",
      "Group count  : [7, 973, 16, 4]\n",
      "-- Generation 68 --\n",
      "Fitness avg    :3.934547482536697\n",
      "Fitness max    :4.222222222222222\n",
      "Group count  : [7, 977, 10, 6]\n",
      "-- Generation 69 --\n",
      "Fitness avg    :3.949597122963007\n",
      "Fitness max    :4.2439024390243905\n",
      "Group count  : [6, 981, 10, 3]\n",
      "-- Generation 70 --\n",
      "Fitness avg    :3.9568953620625926\n",
      "Fitness max    :4.157894736842105\n",
      "Group count  : [5, 985, 6, 4]\n",
      "-- Generation 71 --\n",
      "Fitness avg    :3.958411386188737\n",
      "Fitness max    :4.2105263157894735\n",
      "Group count  : [2, 986, 11, 1]\n",
      "-- Generation 72 --\n",
      "Fitness avg    :3.9482050563303495\n",
      "Fitness max    :4.205128205128205\n",
      "Group count  : [4, 984, 8, 4]\n",
      "-- Generation 73 --\n",
      "Fitness avg    :3.956023995747085\n",
      "Fitness max    :4.222222222222222\n",
      "Group count  : [2, 984, 10, 4]\n",
      "-- Generation 74 --\n",
      "Fitness avg    :3.928286687387304\n",
      "Fitness max    :4.294117647058823\n",
      "Group count  : [2, 980, 11, 7]\n",
      "-- Generation 75 --\n",
      "Fitness avg    :3.955049589930263\n",
      "Fitness max    :4.157894736842105\n",
      "Group count  : [0, 988, 8, 4]\n",
      "-- Generation 76 --\n",
      "Fitness avg    :3.964645666344777\n",
      "Fitness max    :4.176470588235294\n",
      "Group count  : [3, 988, 8, 1]\n",
      "-- Generation 77 --\n",
      "Fitness avg    :3.941486467005375\n",
      "Fitness max    :4.216216216216216\n",
      "Group count  : [8, 981, 8, 3]\n",
      "-- Generation 78 --\n",
      "Fitness avg    :3.9630138495542186\n",
      "Fitness max    :4.1875\n",
      "Group count  : [5, 990, 3, 2]\n",
      "-- Generation 79 --\n",
      "Fitness avg    :3.982007450760813\n",
      "Fitness max    :4.176470588235294\n",
      "Group count  : [0, 996, 3, 1]\n",
      "-- Generation 80 --\n",
      "Fitness avg    :3.944416125106933\n",
      "Fitness max    :4.2105263157894735\n",
      "Group count  : [4, 984, 7, 5]\n",
      "-- Generation 81 --\n",
      "Fitness avg    :3.950180852196867\n",
      "Fitness max    :4.181818181818182\n",
      "Group count  : [2, 985, 8, 5]\n",
      "-- Generation 82 --\n",
      "Fitness avg    :3.960523600333374\n",
      "Fitness max    :4.125\n",
      "Group count  : [2, 990, 3, 5]\n",
      "-- Generation 83 --\n",
      "Fitness avg    :3.9691784288328265\n",
      "Fitness max    :4.142857142857143\n",
      "Group count  : [4, 991, 4, 1]\n",
      "-- Generation 84 --\n",
      "Fitness avg    :3.96003532817756\n",
      "Fitness max    :4.2\n",
      "Group count  : [3, 985, 10, 2]\n",
      "-- Generation 85 --\n",
      "Fitness avg    :3.9642822504756374\n",
      "Fitness max    :4.222222222222222\n",
      "Group count  : [6, 987, 6, 1]\n",
      "-- Generation 86 --\n",
      "Fitness avg    :3.959443505978909\n",
      "Fitness max    :4.176470588235294\n",
      "Group count  : [3, 988, 5, 4]\n",
      "-- Generation 87 --\n",
      "Fitness avg    :3.9424931287689953\n",
      "Fitness max    :4.193548387096774\n",
      "Group count  : [6, 986, 4, 4]\n",
      "-- Generation 88 --\n",
      "Fitness avg    :3.9531204039244208\n",
      "Fitness max    :4.157894736842105\n",
      "Group count  : [8, 986, 3, 3]\n",
      "-- Generation 89 --\n",
      "Fitness avg    :3.967029097739696\n",
      "Fitness max    :4.142857142857143\n",
      "Group count  : [4, 991, 2, 3]\n",
      "-- Generation 90 --\n",
      "Fitness avg    :3.9737045529848456\n",
      "Fitness max    :4.181818181818182\n",
      "Group count  : [5, 990, 3, 2]\n",
      "-- Generation 91 --\n",
      "Fitness avg    :3.961459570055044\n",
      "Fitness max    :4.133333333333334\n",
      "Group count  : [2, 991, 3, 4]\n",
      "-- Generation 92 --\n",
      "Fitness avg    :3.9707707175254368\n",
      "Fitness max    :4.162162162162162\n",
      "Group count  : [6, 989, 3, 2]\n",
      "-- Generation 93 --\n",
      "Fitness avg    :3.9577112018072693\n",
      "Fitness max    :4.193548387096774\n",
      "Group count  : [6, 983, 5, 6]\n",
      "-- Generation 94 --\n",
      "Fitness avg    :3.961822925000863\n",
      "Fitness max    :4.176470588235294\n",
      "Group count  : [6, 988, 5, 1]\n",
      "-- Generation 95 --\n",
      "Fitness avg    :3.951665691119698\n",
      "Fitness max    :4.15\n",
      "Group count  : [5, 987, 3, 5]\n",
      "-- Generation 96 --\n",
      "Fitness avg    :3.9617703921113474\n",
      "Fitness max    :4.206896551724138\n",
      "Group count  : [9, 987, 2, 2]\n",
      "-- Generation 97 --\n",
      "Fitness avg    :3.9604278744333614\n",
      "Fitness max    :4.176470588235294\n",
      "Group count  : [5, 987, 4, 4]\n",
      "-- Generation 98 --\n",
      "Fitness avg    :3.9586442610873815\n",
      "Fitness max    :4.153846153846154\n",
      "Group count  : [5, 990, 2, 3]\n",
      "-- Generation 99 --\n",
      "Fitness avg    :3.9602349713796468\n",
      "Fitness max    :4.214285714285714\n",
      "Group count  : [6, 986, 7, 1]\n",
      "-- Generation 100 --\n",
      "Fitness avg    :3.9524732789273256\n",
      "Fitness max    :4.1875\n",
      "Group count  : [3, 986, 6, 5]\n"
     ]
    }
   ],
   "source": [
    "from deap import base\n",
    "from deap import tools\n",
    "import random\n",
    "\n",
    "# set evolution probabilities \n",
    "INDPB = 0.1\n",
    "CXPB  = 0.1\n",
    "MUTPB = 0.5\n",
    "# set number of generations\n",
    "NGEN  = 100\n",
    "\n",
    "# setup DEAP toolbox of methods used to evolve\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_float\", random.uniform, -1.0, 1.0)\n",
    "toolbox.register(\"individual\", Player, IND_SIZE)\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0.0, sigma=0.5, indpb=INDPB)\n",
    "toolbox.register(\"pop\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# initialise neural network\n",
    "network = NeuralNetwork(numInputNodes, numHiddenNodes, numOutputNodes)\n",
    "\n",
    "# setup population\n",
    "pop = toolbox.pop(n=POP)\n",
    "print(\"-- Generation 1 --\")\n",
    "# initial play game, allowing agents to swap groups using neural network\n",
    "pop[:] = playGameAndEvolve(pop, network)\n",
    "# get results of game\n",
    "popFitness = fitnessStats(pop)\n",
    "# output generation data\n",
    "print(\"Fitness avg    :\"+str(popFitness[\"mean\"]))\n",
    "print(\"Fitness max    :\"+str(popFitness[\"max\"]))\n",
    "print(\"Group count  : \"+str(countGroups(pop)))\n",
    "\n",
    "# run for all generations\n",
    "for g in range(2,NGEN+1):\n",
    "  print(\"-- Generation %i --\" % g)\n",
    "  # use tournament selection to select offspring\n",
    "  offspring = toolbox.select(pop, len(pop))\n",
    "  # clone selected offspring\n",
    "  offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "  # perform crossover for all combinations of offspring (mating)\n",
    "  for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "    # only mate if under crossover probability threshold\n",
    "    if random.random() < CXPB:\n",
    "      toolbox.mate(child1.weights, child2.weights)\n",
    "\n",
    "  # mutate an agent\n",
    "  for mutant in offspring:\n",
    "     # only mutate if under mutation probability threshold\n",
    "    if random.random() < MUTPB:\n",
    "      toolbox.mutate(mutant.weights)\n",
    "      # only change group if under independent probability threshold \n",
    "      if (random.random() < INDPB):\n",
    "        mutant.startingGroup = random.randint(0,3)\n",
    "\n",
    "  # reset all agents in the population\n",
    "  for person in offspring:\n",
    "    person.reset()\n",
    "  \n",
    "  # play game, allowing agents to swap groups using neural network\n",
    "  pop[:] = playGameAndEvolve(offspring, network)\n",
    "  # get results of game\n",
    "  popFitness = fitnessStats(pop)\n",
    "  # output generation data\n",
    "  print(\"Fitness avg    :\"+str(popFitness[\"mean\"]))\n",
    "  print(\"Fitness max    :\"+str(popFitness[\"max\"]))\n",
    "  print(\"Group count  : \"+str(countGroups(pop)))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
